# -*- coding: utf-8 -*-
"""tweetsExtraction(Colab1).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1pKHave5J8xAnlsXeYXNaYXBN9yX1CC3c

**Import statements**
"""

import tweepy
import sys
import pandas as pd

#class MyStreamListener(tweepy.StreamListener):
 #   def on_status(self,status):
  #      print(status.text)
  #  def on_error(self,status_code):
   #     print(status_code)

consumer_key = "zKWjOkcSkMCuPQ4Ybd7oqY7E8"
consumer_secret = "Jgl9HOTj5ruahA3QrHl4FwVQxHq2RgDZ45kUUaEOwsoP2pFmbO"
access_token = "1444973694275686403-JM5cvL80eQGsAgPt9ZS9aR6gfbrnHL"
access_token_secret = "nKRwdyGfdZwPudsUk861OIxc0qJ3yTpiXWXgp0ZJJRMgq"

auth = tweepy.OAuthHandler(consumer_key,consumer_secret)
auth.set_access_token(access_token, access_token_secret)
api = tweepy.API(auth)

#search_words = "Tata Safari" #"google"
date_since = "2018-1-1"

#tweets = tweepy.Cursor(api.search, q=search_words, lang="en", since=date_since,).items(500)
#posts = api.user_timeline(screen_name = "Tata_Safari", count=200, lang="en", tweet_mode="extended")

# Iterate and print tweets
#for tweet in tweets:
   # print(tweet.text)

#df = pd.DataFrame([tweet.full_text for tweet in tweets], columns=['Tweets'])
#df.head()

#tweets_df.to_csv('data1.csv')

new_search = "Mahindra XUV"
new_search

tweets = tweepy.Cursor(api.search, 
                           q=new_search,
                           lang="en",
                          since=date_since
                       ).items(5000)

users_locs = [[tweet.user.screen_name, tweet.user.location, tweet.text] for tweet in tweets]
users_locs



tweet_text = pd.DataFrame(data=users_locs, 
                    columns=['user', "location",'tweet'])
tweet_text

from google.colab import files
import pandas as pd
tweet_text.to_csv('XUV700.csv')
files.download('XUV700.csv')